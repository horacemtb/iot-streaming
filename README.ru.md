# Конвейер обработки данных IoT с использованием ELT-пайплайна

__Цель проекта__: Разработать систему для сбора, обработки, хранения и визуализации телеметрических данных IoT. Данные собираются в реальном времени с помощью Apache NiFi, хранятся в объектном хранилище MinIO и загружаются в хранилище данных PostgreSQL для аналитической обработки. Apache Airflow оркестрирует процессы обработки и преобразования данных, а PGAdmin и Metabase обеспечивают анализ и визуализацию агрегированных данных.

## Данные

Этот раздел содержит краткое описание данных, использованных в проекте.

__Источник данных__: https://www.kaggle.com/datasets/garystafford/environmental-sensor-data-132k

Данные были собраны с помощью сенсоров, подключенных к трем устройствам на базе Raspberry Pi, расположенным в местах с различными условиями окружающей среды:

| ID устройства     | Условия окружающей среды                 |
|-------------------|------------------------------------------|
| 00:0f:00:70:91:0a | Стабильные, более прохладные и влажные   |
| 1c:bf:ce:15:ec:4d | Значительные колебания темп. и влажности |
| b8:27:eb:bf:9d:51 | Стабильные, более теплые и сухие         |

Каждое устройство регулярно собирало данные по семи показателям. Для этого проекта использовались шесть из них: температура, влажность, угарный газ (CO), сжиженный углеводородный газ (LPG), дым и освещенность. Переменная "движение" была исключена, т.к. не представляла интереса для целей проекта из-за очень малой дисперсии. Данные охватывают период с 12.07.2020 00:01:00 UTC по 19.07.2020 23:59:59 UTC.

__Столбцы данных и их описание__:

| Столбец  | Описание                           | Ед. изм. |
|----------|------------------------------------|----------|
| ts       | Временная метка события            | epoch    |
| device   | Уникальный ID устройства           | string   |
| co       | Угарный газ                        | ppm (%)  |
| humidity | Влажность                          | %        |
| lpg      | Сжиженный углеводородный газ       | ppm (%)  |
| smoke    | Дым                                | ppm (%)  |
| temp     | Температура                        | °C       |
| light    | Обнаружение света                  | boolean  |

## Архитектура

Схема архитектуры проекта, иллюстрирующая жизненный цикл данных от сбора до хранения, анализа и визуализаций.

![Alt text](https://github.com/horacemtb/iot-streaming/blob/main/images/iot-streaming.png)

## Компоненты системы

Детальное описание каждого компонента конвейера обработки данных.

1. __Виртуальная машина dmitry-airflow__

- __Роль__: Хостинг Airflow для оркестрации обработки данных
- __Развертывание__: Yandex Compute Cloud.
- __Описание__: Выполняет DAG-и Airflow, которые извлекают сырые данные из MinIO, обрабатывают их и сохраняют в слоях DDS и Datamart в БД PostgreSQL. DAG-и запускаются каждые 15 и 60 минут. Для подключения к MinIO используется библиотека boto3, для подключения к PostgreSQL — PostgresHooks.

2. __Виртуальная машина dmitry-de__

- __Роль__: Хостинг NiFi, MinIO, PostgreSQL, PGAdmin и Metabase для сбора, хранения и визуализации данных
- __Развертывание__: Yandex Compute Cloud.
- __Описание__: Управляет сбором данных с IoT-устройств через NiFi. Отвечает за хранение сырых данных в MinIO и обработанных данных в PostgreSQL. Обеспечивает возможность построения дашбордов в Metabase. Каждый сервис работает в Docker-контейнере. Для взаимодействия сервисов используется Docker Compose.

3. __Apache NiFi__

- __Роль__: Сбор сырых данных и деление их на батчи
- __Развертывание__: Запущен как Docker-контейнер на виртуальной машине dmitry-de.
- __Описание__: Принимает поток данных IoT через процессор ListenHTTP. Данные предварительно обрабатываются с помощью процессора MergeContent для объединения записей в батчи по 1000. Процессоры ExecuteScript и UpdateAttribute используются для задания имени каждой группы на основе временной метки. Обработанные данные сохраняются в MinIO через процессор PutS3Object.

4. __MinIO__

- __Роль__: Объектное хранилище для сырых данных
- __Развертывание__: Запущен как Docker-контейнер на виртуальной машине dmitry-de.
- __Описание__: Предоставляет масштабируемое хранилище, совместимое с S3, для больших объемов данных IoT, хранящихся в виде txt файлов с временными метками.

5. __Apache Airflow__

- __Роль__: Оркестрация и планирование процессов обработки данных
- __Развертывание__: Запущен на виртуальной машине dmitry-airflow.
- __Описание__: Оркестрирует и планирует процессы обработки данных IoT, с помощью которых они поступают из озера данных в DDS и Datamart слои DWH на основе PostgreSQL. Основные DAG-и включают:
    - __create_dds_dag__ и __create_datamart_dag__: Инициализируют таблицы слоёв DDS (dds_iot_database) и Datamart (datamart_iot_database) в PostgreSQL.
    - __drop_dds_dag__ и __drop_datamart_dag__: Удаляют все таблицы слоёв DDS и Datamart.
    - __s3_to_dds_dag__: Запускается каждые 15 минут для извлечения данных из MinIO, агрегирует данные по минутам и загружает их в слой DDS.
    - __dds_to_dm_dag__: Запускается каждый час для извлечения данных из слоя DDS, обработки и почасовой агрегации, переноса данных в таблицы слоя Datamart для анализа и визуализации.

6. __PostgreSQL__

- __Роль__: Хранилище данных
- __Развертывание__: Запущен как Docker-контейнер на виртуальной машине dmitry-de.
- __Описание__: Хранит обработанные данные IoT в структурированном виде, разделяя их на слои DDS и Datamart для эффективного выполнения запросов и визуализации:
    - __Слой DDS (dds_iot_database)__: Хранит данные с минутной детализацией для исторического анализа.
    - __Слой Datamart (datamart_iot_database)__: Содержит почасовые агрегаты для пользователей, включая:
        - dm_iot_average: Средние значения переменных за час.
        - dm_iot_extreme: Минимальные и максимальные значения за час.
        - dm_iot_count: Количество записей за час.
        - dm_iot_ml: Статистические признаки, подготовленные для моделей машинного обучения.

7. __PGAdmin__

- __Роль__: Интерфейс для управления базой данных
- __Развертывание__: Запущен как Docker-контейнер на виртуальной машине dmitry-de.
- __Описание__: Веб-интерфейс для управления и выполнения запросов к PostgreSQL. Позволяет визуально проверять таблицы DDS и Datamart на предмет корректности наполнения, а также выполнять SQL-запросы.

8. __Metabase__

- __Роль__: Визуализация данных
- __Развертывание__: Запущен как Docker-контейнер на виртуальной машине dmitry-de.
- __Описание__: Подключается напрямую к базе данных datamart_iot_database в PostgreSQL, используя агрегированные таблицы данных для визуализации. Дашборды предоставляют аналитику по данным IoT.

9. __Docker__

- __Роль__: Контейнеризация и управление сервисами
- __Развертывание__: Запущен на виртуальной машине dmitry-de.
- __Описание__: Управляется Docker Compose, который настраивает взаимодействие контейнеров.

## Конвейер

Пошаговое описание процесса обработки данных, от сбора сырых данных до преобразований и визуализаций.

1. __Генерация и сбор данных__

- __Генерация данных__:  Система симулирует поток данных IoT об условиях окружающей среды. Каждая запись отправляется в виде одной строки, где все переменные (время, ID устройства, CO, влажность, LPG, дым, температура, свет) разделены пробелами. Данные могут генерироваться двумя способами:

    - __Генерация случайных данных__: Скрипт generate_dummy_data.py создает случайные значения для каждой переменной, включая выбросы и пропуски, чтобы симулировать реальные неисправности устройств. Эти записи отправляются как HTTP POST запросы на выделенный IP и порт Apache NiFi. Основные аргументы:

        - url: NiFi IP и порт
        - requests_per_second: количество запросов в секунду для каждого устройства
        - total_requests: общее количество запросов для каждого устройства

    - __Генерация реальных данных__: Скрипт generate_real_data.py считывает реальные исторические данные IoT из CSV-файла в папке raw-data и отправляет каждую запись как HTTP POST запрос на NiFi. Основные аргументы:

        - csv_file: путь к файлу с реальными данными
        - url: NiFi IP и порт
        - requests_per_second: количество запросов в секунду для каждого устройства

- __Сбор данных с помощью Apache NiFi__:

    - ListenHTTP: Процессор ListenHTTP в NiFi принимает каждый HTTP POST запрос и записывает каждую строку данных.
    - MergeContent: Процессор MergeContent объединяет 1 000 записей в один .txt файл для удобства хранения.
    - После объединения записей NiFi извлекает временную метку из последней строки и использует её как имя файла.
    - PutS3Object: Каждый файл загружается в хранилище MinIO с именем в виде извлечённой временной метки, упрощая дальнейший доступ к файлам.

2. __Хранение данных в MinIO__

Созданные .txt файлы сохраняются в бакете env-telemetry-data в MinIO.

3. __Преобразование данных и загрузка в DDS PostgreSQL__

DAG s3_to_dds_dag.py в Airflow запускается каждые 15 минут и выполняет следующие операции:

- Извлекает последнюю временную метку из слоя DDS и выбирает все новые .txt файлы в MinIO с именами позже этой метки.
- Каждый .txt файл разделяется на отдельные записи, которые все вместе конвертируются в один DataFrame.
- Отбирает данные, включающие только полные минуты.
- Группирует данные по минутам и вычисляет средние значения всех переменных.
- Чистит данные, удаляя строки с NaN значениями и выбросы.
- Загружает преобразованные данные в DDS PostgreSQL.

4. __Агрегация и создание признаков в слое DataMart__

DAG dds_to_dm_dag.py в Airflow запускается каждые 60 минут и выполняет следующие задачи:

- Извлекает последнюю временную метку из слоя DataMart и выбирает все записи из уровня DDS позднее этой метки.
- Отбирает данные, включающие только полные часы.
- Группирет данные по часам и вычисляет признаки для анализа данных и машинного обучения, заполняя следующие таблицы:

    - dm_iot_average: хранит средние значения по каждой переменной за час.
    - dm_iot_extreme: хранит максимальные и минимальные значения по каждой переменной, отражая экстремальные условия.
    - dm_iot_count: отслеживает количество записей в час для каждого устройства.
    - dm_iot_ml: содержит признаки для машинного обучения, такие как: изменения значений переменных за час, соотношения разных показателей и другие статистические метрики.

- Загружает агрегированные данные в таблицы слоя DataMart.

5. __Бизнес-аналитика и визуализация в Metabase__

- Metabase подключается к PostgreSQL, что позволяет напрямую обращаться к таблицам слоя DataMart для запросов и визуализации.
- Ключевые метрики, такие как средние, минимальные и максимальные значения по температуре, влажности, CO, LPG и дыму, отображаются на временных графиках.
- Пользователи могут фильтровать данные по device_id и диапазону времени.
- Отдельная вкладка отслеживает количество записей в час (в норме 60), чтобы убедиться в стабильной работе системы.

## Настройки и команды

Инструкции по установке и команды для инициализации и управления каждым компонентом конвейера данных.

1. Убедитесь, что у вас развернуты две виртуальные машины в Yandex Cloud:

![Alt text](https://github.com/horacemtb/iot-streaming/blob/main/images/YandexCloud%20VMs.png)

2. Настройте Airflow для выполнения DAG-ов:

На виртуальной машине dmitry-airflow:

- Скопируйте DAG-и из папки airflow-dags в папку /dags на виртуальной машине.

- Установите необходимые библиотеки:

```
sudo python3 -m pip install boto3 python-dotenv
```

- Настройте подключение к S3, добавив переменные окружения в файл airflow-dags/.env.

- Настройте соединения с PostgreSQL в интерфейсе Airflow, как показано на скриншотах:

![Alt text](https://github.com/horacemtb/iot-streaming/blob/main/images/airflow_dds_connection.png)
![Alt text](https://github.com/horacemtb/iot-streaming/blob/main/images/airflow_dm_connection.png)

3. Настройте основные сервисы на виртуальной машине dmitry-de:

- Добавьте креды в файл docker-compose.

- Разверните контейнеры (команда ниже требуется только при первом запуске):

```
docker-compose up -d
```

- Для последующих запусков используйте команды для включения и остановки контейнеров без потери данных:

```
docker-compose start
docker-compose stop
```

- Зайдите в командную строку контейнера PostgreSQL и создайте две базы данных:

```
docker exec -it postgres psql -U ... -d postgres
CREATE DATABASE dds_iot_database;
CREATE DATABASE datamart_iot_database;
\q
```

- Убедитесь, что MinIO запущен на указанном порту:

![Alt text](https://github.com/horacemtb/iot-streaming/blob/main/images/minio.png)

- Настройте NiFi, как показано на скриншотах ниже:

![Alt text](https://github.com/horacemtb/iot-streaming/blob/main/images/ni-fi.png)
![Alt text](https://github.com/horacemtb/iot-streaming/blob/main/images/ni-fi_listenhttp_config.png)
![Alt text](https://github.com/horacemtb/iot-streaming/blob/main/images/ni-fi_mergecontent_config.png)
![Alt text](https://github.com/horacemtb/iot-streaming/blob/main/images/ni-fi_executescript_config.png)
![Alt text](https://github.com/horacemtb/iot-streaming/blob/main/images/ni-fi_updateattribute_config.png)
![Alt text](https://github.com/horacemtb/iot-streaming/blob/main/images/ni-fi_puts3object_config.png)

4. Запустите конвейер данных:

На виртуальной машине dmitry-airflow:

- Запустите DAG-и create_dds_dag и create_datamart_dag для создания пустых таблиц слоёв DDS и DataMart.
- Запустите DAG-и s3_to_dds_dag и dds_to_dm_dag для начала обработки данных.

5. Запустите генерацию данных:

На виртуальной машине dmitry-de выберите один из следующих вариантов для генерации данных:

- Синтетические данные:

```
python3 generate_dummy_data.py --url http://127.0.0.1:8081/loglistener --requests_per_second 10 --total_requests 10000
```

- Реальные данные:

```
python3 generate_real_data.py --csv_file raw-data/iot_telemetry_data.csv --url http://127.0.0.1:8081/loglistener --requests_per_second 10
```

![Alt text](https://github.com/horacemtb/iot-streaming/blob/main/images/send_real_data.png)

6. Проверьте, что данные обрабатываются корректно, а у контейнера Metabase есть покдключение к таблицам слоя DataMart:

- Убедитесь, что DAG-и Airflow успешно завершены в соответствии с заданным расписанием:

![Alt text](https://github.com/horacemtb/iot-streaming/blob/main/images/s3_to_dds_dag.png)
![Alt text](https://github.com/horacemtb/iot-streaming/blob/main/images/dds_to_dm_dag.png)

- Откройте интерфейс Metabase, чтобы убедиться, что данные из таблиц DataMart были успешно загружены:

![Alt text](https://github.com/horacemtb/iot-streaming/blob/main/images/metabase_connected.png)